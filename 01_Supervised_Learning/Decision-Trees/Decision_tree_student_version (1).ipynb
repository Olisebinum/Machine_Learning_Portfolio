{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "047f9f94",
   "metadata": {
    "id": "047f9f94"
   },
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Code_challenge.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f662d169",
   "metadata": {
    "id": "f662d169"
   },
   "source": [
    "# Code challenge: Decision trees\n",
    "¬© ExploreAI Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26af890c",
   "metadata": {
    "id": "26af890c"
   },
   "source": [
    "In this code challenge, we will test our knowledge of the fundamental concepts of decision trees by implementing a decision tree regression model and analysing its RMSLE.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3b5c1e",
   "metadata": {
    "id": "3e3b5c1e"
   },
   "source": [
    "‚ö†Ô∏è **Note that this code challenge is graded and will contribute to your overall marks for this module. Submit this notebook for grading. Note that the names of the functions are different in this notebook. Transfer the code in your notebook to this submission notebook**\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- **Do not add or remove cells in this notebook. Do not edit or remove the `### START FUNCTION` or `### END FUNCTION` comments. Do not add any code outside of the functions you are required to edit. Doing any of this will lead to a mark of 0%!**\n",
    "\n",
    "- Answer the questions according to the specifications provided.\n",
    "\n",
    "- Use the given cell in each question to see if your function matches the expected outputs.\n",
    "\n",
    "- Do not hard-code answers to the questions.\n",
    "\n",
    "- The use of StackOverflow, Google, and other online tools is permitted. However, copying a fellow student's code is not permissible and is considered a breach of the Honour code. Doing this will result in a mark of 0%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a275af89",
   "metadata": {
    "id": "a275af89"
   },
   "source": [
    "We begin by importing the necessary packages for the challenges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7918a99c",
   "metadata": {
    "executionInfo": {
     "elapsed": 3516,
     "status": "ok",
     "timestamp": 1762869680246,
     "user": {
      "displayName": "olise ossai",
      "userId": "04328672551785049802"
     },
     "user_tz": 360
    },
    "id": "7918a99c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022dbac7",
   "metadata": {
    "id": "022dbac7"
   },
   "source": [
    "## The dataset\n",
    "\n",
    "The dataset contains population data for various countries over the years from 1960 to 2017. Each row corresponds to a specific country, identified by a country code, and each column represents a year. The values within the dataset represent the population count for each country in the corresponding year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c17898c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1762869680566,
     "user": {
      "displayName": "olise ossai",
      "userId": "04328672551785049802"
     },
     "user_tz": 360
    },
    "id": "9c17898c",
    "outputId": "38d26323-b784-4cce-e84e-53a3a0eb96e3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Country Code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "1960",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1961",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1962",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1963",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1964",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1965",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1966",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1967",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1968",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1969",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1970",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1971",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1972",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1973",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1974",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1975",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1976",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1977",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1978",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1979",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1980",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1981",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1982",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1983",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1984",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1985",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1986",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1987",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1988",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1989",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1990",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1991",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1992",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1993",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1994",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1995",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1996",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1997",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1998",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1999",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2000",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2001",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2002",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2003",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2004",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2005",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2006",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2007",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2008",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2009",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2010",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2011",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2012",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2013",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2014",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2015",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2016",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2017",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "29ee0894-a9fe-46c5-ae98-7615cb96f6f8",
       "rows": [
        [
         "ABW",
         "54211.0",
         "55438.0",
         "56225.0",
         "56695.0",
         "57032.0",
         "57360.0",
         "57715.0",
         "58055.0",
         "58386.0",
         "58726.0",
         "59063.0",
         "59440.0",
         "59840.0",
         "60243.0",
         "60528.0",
         "60657.0",
         "60586.0",
         "60366.0",
         "60103.0",
         "59980.0",
         "60096.0",
         "60567.0",
         "61345.0",
         "62201.0",
         "62836.0",
         "63026.0",
         "62644.0",
         "61833.0",
         "61079.0",
         "61032.0",
         "62149.0",
         "64622.0",
         "68235.0",
         "72504.0",
         "76700.0",
         "80324.0",
         "83200.0",
         "85451.0",
         "87277.0",
         "89005.0",
         "90853.0",
         "92898.0",
         "94992.0",
         "97017.0",
         "98737.0",
         "100031.0",
         "100832.0",
         "101220.0",
         "101353.0",
         "101453.0",
         "101669.0",
         "102053.0",
         "102577.0",
         "103187.0",
         "103795.0",
         "104341.0",
         "104822.0",
         "105264.0"
        ],
        [
         "AFG",
         "8996351.0",
         "9166764.0",
         "9345868.0",
         "9533954.0",
         "9731361.0",
         "9938414.0",
         "10152331.0",
         "10372630.0",
         "10604346.0",
         "10854428.0",
         "11126123.0",
         "11417825.0",
         "11721940.0",
         "12027822.0",
         "12321541.0",
         "12590286.0",
         "12840299.0",
         "13067538.0",
         "13237734.0",
         "13306695.0",
         "13248370.0",
         "13053954.0",
         "12749645.0",
         "12389269.0",
         "12047115.0",
         "11783050.0",
         "11601041.0",
         "11502761.0",
         "11540888.0",
         "11777609.0",
         "12249114.0",
         "12993657.0",
         "13981231.0",
         "15095099.0",
         "16172719.0",
         "17099541.0",
         "17822884.0",
         "18381605.0",
         "18863999.0",
         "19403676.0",
         "20093756.0",
         "20966463.0",
         "21979923.0",
         "23064851.0",
         "24118979.0",
         "25070798.0",
         "25893450.0",
         "26616792.0",
         "27294031.0",
         "28004331.0",
         "28803167.0",
         "29708599.0",
         "30696958.0",
         "31731688.0",
         "32758020.0",
         "33736494.0",
         "34656032.0",
         "35530081.0"
        ],
        [
         "AGO",
         "5643182.0",
         "5753024.0",
         "5866061.0",
         "5980417.0",
         "6093321.0",
         "6203299.0",
         "6309770.0",
         "6414995.0",
         "6523791.0",
         "6642632.0",
         "6776381.0",
         "6927269.0",
         "7094834.0",
         "7277960.0",
         "7474338.0",
         "7682479.0",
         "7900997.0",
         "8130988.0",
         "8376147.0",
         "8641521.0",
         "8929900.0",
         "9244507.0",
         "9582156.0",
         "9931562.0",
         "10277321.0",
         "10609042.0",
         "10921037.0",
         "11218268.0",
         "11513968.0",
         "11827237.0",
         "12171441.0",
         "12553446.0",
         "12968345.0",
         "13403734.0",
         "13841301.0",
         "14268994.0",
         "14682284.0",
         "15088981.0",
         "15504318.0",
         "15949766.0",
         "16440924.0",
         "16983266.0",
         "17572649.0",
         "18203369.0",
         "18865716.0",
         "19552542.0",
         "20262399.0",
         "20997687.0",
         "21759420.0",
         "22549547.0",
         "23369131.0",
         "24218565.0",
         "25096150.0",
         "25998340.0",
         "26920466.0",
         "27859305.0",
         "28813463.0",
         "29784193.0"
        ],
        [
         "ALB",
         "1608800.0",
         "1659800.0",
         "1711319.0",
         "1762621.0",
         "1814135.0",
         "1864791.0",
         "1914573.0",
         "1965598.0",
         "2022272.0",
         "2081695.0",
         "2135479.0",
         "2187853.0",
         "2243126.0",
         "2296752.0",
         "2350124.0",
         "2404831.0",
         "2458526.0",
         "2513546.0",
         "2566266.0",
         "2617832.0",
         "2671997.0",
         "2726056.0",
         "2784278.0",
         "2843960.0",
         "2904429.0",
         "2964762.0",
         "3022635.0",
         "3083605.0",
         "3142336.0",
         "3227943.0",
         "3286542.0",
         "3266790.0",
         "3247039.0",
         "3227287.0",
         "3207536.0",
         "3187784.0",
         "3168033.0",
         "3148281.0",
         "3128530.0",
         "3108778.0",
         "3089027.0",
         "3060173.0",
         "3051010.0",
         "3039616.0",
         "3026939.0",
         "3011487.0",
         "2992547.0",
         "2970017.0",
         "2947314.0",
         "2927519.0",
         "2913021.0",
         "2905195.0",
         "2900401.0",
         "2895092.0",
         "2889104.0",
         "2880703.0",
         "2876101.0",
         "2873457.0"
        ],
        [
         "AND",
         "13411.0",
         "14375.0",
         "15370.0",
         "16412.0",
         "17469.0",
         "18549.0",
         "19647.0",
         "20758.0",
         "21890.0",
         "23058.0",
         "24276.0",
         "25559.0",
         "26892.0",
         "28232.0",
         "29520.0",
         "30705.0",
         "31777.0",
         "32771.0",
         "33737.0",
         "34818.0",
         "36067.0",
         "37500.0",
         "39114.0",
         "40867.0",
         "42706.0",
         "44600.0",
         "46517.0",
         "48455.0",
         "50434.0",
         "52448.0",
         "54509.0",
         "56671.0",
         "58888.0",
         "60971.0",
         "62677.0",
         "63850.0",
         "64360.0",
         "64327.0",
         "64142.0",
         "64370.0",
         "65390.0",
         "67341.0",
         "70049.0",
         "73182.0",
         "76244.0",
         "78867.0",
         "80991.0",
         "82683.0",
         "83861.0",
         "84462.0",
         "84449.0",
         "83751.0",
         "82431.0",
         "80788.0",
         "79223.0",
         "78014.0",
         "77281.0",
         "76965.0"
        ]
       ],
       "shape": {
        "columns": 58,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>1967</th>\n",
       "      <th>1968</th>\n",
       "      <th>1969</th>\n",
       "      <th>...</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country Code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ABW</th>\n",
       "      <td>54211.0</td>\n",
       "      <td>55438.0</td>\n",
       "      <td>56225.0</td>\n",
       "      <td>56695.0</td>\n",
       "      <td>57032.0</td>\n",
       "      <td>57360.0</td>\n",
       "      <td>57715.0</td>\n",
       "      <td>58055.0</td>\n",
       "      <td>58386.0</td>\n",
       "      <td>58726.0</td>\n",
       "      <td>...</td>\n",
       "      <td>101353.0</td>\n",
       "      <td>101453.0</td>\n",
       "      <td>101669.0</td>\n",
       "      <td>102053.0</td>\n",
       "      <td>102577.0</td>\n",
       "      <td>103187.0</td>\n",
       "      <td>103795.0</td>\n",
       "      <td>104341.0</td>\n",
       "      <td>104822.0</td>\n",
       "      <td>105264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFG</th>\n",
       "      <td>8996351.0</td>\n",
       "      <td>9166764.0</td>\n",
       "      <td>9345868.0</td>\n",
       "      <td>9533954.0</td>\n",
       "      <td>9731361.0</td>\n",
       "      <td>9938414.0</td>\n",
       "      <td>10152331.0</td>\n",
       "      <td>10372630.0</td>\n",
       "      <td>10604346.0</td>\n",
       "      <td>10854428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27294031.0</td>\n",
       "      <td>28004331.0</td>\n",
       "      <td>28803167.0</td>\n",
       "      <td>29708599.0</td>\n",
       "      <td>30696958.0</td>\n",
       "      <td>31731688.0</td>\n",
       "      <td>32758020.0</td>\n",
       "      <td>33736494.0</td>\n",
       "      <td>34656032.0</td>\n",
       "      <td>35530081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGO</th>\n",
       "      <td>5643182.0</td>\n",
       "      <td>5753024.0</td>\n",
       "      <td>5866061.0</td>\n",
       "      <td>5980417.0</td>\n",
       "      <td>6093321.0</td>\n",
       "      <td>6203299.0</td>\n",
       "      <td>6309770.0</td>\n",
       "      <td>6414995.0</td>\n",
       "      <td>6523791.0</td>\n",
       "      <td>6642632.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21759420.0</td>\n",
       "      <td>22549547.0</td>\n",
       "      <td>23369131.0</td>\n",
       "      <td>24218565.0</td>\n",
       "      <td>25096150.0</td>\n",
       "      <td>25998340.0</td>\n",
       "      <td>26920466.0</td>\n",
       "      <td>27859305.0</td>\n",
       "      <td>28813463.0</td>\n",
       "      <td>29784193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALB</th>\n",
       "      <td>1608800.0</td>\n",
       "      <td>1659800.0</td>\n",
       "      <td>1711319.0</td>\n",
       "      <td>1762621.0</td>\n",
       "      <td>1814135.0</td>\n",
       "      <td>1864791.0</td>\n",
       "      <td>1914573.0</td>\n",
       "      <td>1965598.0</td>\n",
       "      <td>2022272.0</td>\n",
       "      <td>2081695.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2947314.0</td>\n",
       "      <td>2927519.0</td>\n",
       "      <td>2913021.0</td>\n",
       "      <td>2905195.0</td>\n",
       "      <td>2900401.0</td>\n",
       "      <td>2895092.0</td>\n",
       "      <td>2889104.0</td>\n",
       "      <td>2880703.0</td>\n",
       "      <td>2876101.0</td>\n",
       "      <td>2873457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AND</th>\n",
       "      <td>13411.0</td>\n",
       "      <td>14375.0</td>\n",
       "      <td>15370.0</td>\n",
       "      <td>16412.0</td>\n",
       "      <td>17469.0</td>\n",
       "      <td>18549.0</td>\n",
       "      <td>19647.0</td>\n",
       "      <td>20758.0</td>\n",
       "      <td>21890.0</td>\n",
       "      <td>23058.0</td>\n",
       "      <td>...</td>\n",
       "      <td>83861.0</td>\n",
       "      <td>84462.0</td>\n",
       "      <td>84449.0</td>\n",
       "      <td>83751.0</td>\n",
       "      <td>82431.0</td>\n",
       "      <td>80788.0</td>\n",
       "      <td>79223.0</td>\n",
       "      <td>78014.0</td>\n",
       "      <td>77281.0</td>\n",
       "      <td>76965.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   1960       1961       1962       1963       1964  \\\n",
       "Country Code                                                          \n",
       "ABW             54211.0    55438.0    56225.0    56695.0    57032.0   \n",
       "AFG           8996351.0  9166764.0  9345868.0  9533954.0  9731361.0   \n",
       "AGO           5643182.0  5753024.0  5866061.0  5980417.0  6093321.0   \n",
       "ALB           1608800.0  1659800.0  1711319.0  1762621.0  1814135.0   \n",
       "AND             13411.0    14375.0    15370.0    16412.0    17469.0   \n",
       "\n",
       "                   1965        1966        1967        1968        1969  ...  \\\n",
       "Country Code                                                             ...   \n",
       "ABW             57360.0     57715.0     58055.0     58386.0     58726.0  ...   \n",
       "AFG           9938414.0  10152331.0  10372630.0  10604346.0  10854428.0  ...   \n",
       "AGO           6203299.0   6309770.0   6414995.0   6523791.0   6642632.0  ...   \n",
       "ALB           1864791.0   1914573.0   1965598.0   2022272.0   2081695.0  ...   \n",
       "AND             18549.0     19647.0     20758.0     21890.0     23058.0  ...   \n",
       "\n",
       "                    2008        2009        2010        2011        2012  \\\n",
       "Country Code                                                               \n",
       "ABW             101353.0    101453.0    101669.0    102053.0    102577.0   \n",
       "AFG           27294031.0  28004331.0  28803167.0  29708599.0  30696958.0   \n",
       "AGO           21759420.0  22549547.0  23369131.0  24218565.0  25096150.0   \n",
       "ALB            2947314.0   2927519.0   2913021.0   2905195.0   2900401.0   \n",
       "AND              83861.0     84462.0     84449.0     83751.0     82431.0   \n",
       "\n",
       "                    2013        2014        2015        2016        2017  \n",
       "Country Code                                                              \n",
       "ABW             103187.0    103795.0    104341.0    104822.0    105264.0  \n",
       "AFG           31731688.0  32758020.0  33736494.0  34656032.0  35530081.0  \n",
       "AGO           25998340.0  26920466.0  27859305.0  28813463.0  29784193.0  \n",
       "ALB            2895092.0   2889104.0   2880703.0   2876101.0   2873457.0  \n",
       "AND              80788.0     79223.0     78014.0     77281.0     76965.0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population_df = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/AnalyseProject/world_population.csv', index_col='Country Code')\n",
    "population_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de45a481",
   "metadata": {
    "id": "de45a481"
   },
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0b7683",
   "metadata": {
    "id": "5a0b7683",
    "tags": []
   },
   "source": [
    "### Challenge 1: Population growth\n",
    "\n",
    "The world population data spans from 1960 to 2017. We'd like to build a predictive model that can give us the best guess at what the population growth rate in a given year might be. We will calculate the population growth rate as follows:-\n",
    "\n",
    "$$\n",
    "Growth\\_rate = \\frac{current\\_year\\_population - previous\\_year\\_population}{previous\\_year\\_population}\n",
    "$$\n",
    "\n",
    "As such, we can only calculate the growth rate for the year 1961 onwards.\n",
    "\n",
    "Write a function that takes the `population_df` and a `country_code` as input and computes the population growth rate for a given country starting from the year 1961. This function must return a return a 2-d numpy array that contains the year and corresponding growth rate for the country.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take a `population_df` and `country_code` string as input and return a numpy `array` as output.\n",
    "* The array should only have two columns containing the year and the population growth rate, in other words, it should have a shape `(?, 2)` where `?` is the length of the data.\n",
    "* The growth rates should be rounded to 5 decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2ee76ec",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1762869680567,
     "user": {
      "displayName": "olise ossai",
      "userId": "04328672551785049802"
     },
     "user_tz": 360
    },
    "id": "c2ee76ec"
   },
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def get_population_growth_rate_by_country_year(df,country_code):\n",
    "    country_data = df.loc[country_code]\n",
    "    # Extract years and population values, convert column names to integers\n",
    "    years = np.array([int(col) for col in df.columns if col.isdigit()])\n",
    "    population = country_data.values.astype(float)\n",
    "\n",
    "    growth_rates = []\n",
    "    for i in range(1, len(years)): # Start from the second year (1961)\n",
    "        current_year = years[i]\n",
    "        previous_year_population = population[i-1]\n",
    "        current_year_population = population[i]\n",
    "\n",
    "        if previous_year_population == 0: # Avoid division by zero\n",
    "            growth_rate = 0.0\n",
    "        else:\n",
    "            growth_rate = (current_year_population - previous_year_population) / previous_year_population\n",
    "\n",
    "        growth_rates.append([current_year, round(growth_rate, 5)])\n",
    "\n",
    "    return np.array(growth_rates)\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3132bb",
   "metadata": {
    "id": "de3132bb"
   },
   "source": [
    "Input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cc2bcc3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1762869680621,
     "user": {
      "displayName": "olise ossai",
      "userId": "04328672551785049802"
     },
     "user_tz": 360
    },
    "id": "2cc2bcc3",
    "outputId": "c07761c2-dd25-44e8-d685-ea6d517b76ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.961e+03,  2.263e-02],\n",
       "       [ 1.962e+03,  1.420e-02],\n",
       "       [ 1.963e+03,  8.360e-03],\n",
       "       [ 1.964e+03,  5.940e-03],\n",
       "       [ 1.965e+03,  5.750e-03],\n",
       "       [ 1.966e+03,  6.190e-03],\n",
       "       [ 1.967e+03,  5.890e-03],\n",
       "       [ 1.968e+03,  5.700e-03],\n",
       "       [ 1.969e+03,  5.820e-03],\n",
       "       [ 1.970e+03,  5.740e-03],\n",
       "       [ 1.971e+03,  6.380e-03],\n",
       "       [ 1.972e+03,  6.730e-03],\n",
       "       [ 1.973e+03,  6.730e-03],\n",
       "       [ 1.974e+03,  4.730e-03],\n",
       "       [ 1.975e+03,  2.130e-03],\n",
       "       [ 1.976e+03, -1.170e-03],\n",
       "       [ 1.977e+03, -3.630e-03],\n",
       "       [ 1.978e+03, -4.360e-03],\n",
       "       [ 1.979e+03, -2.050e-03],\n",
       "       [ 1.980e+03,  1.930e-03],\n",
       "       [ 1.981e+03,  7.840e-03],\n",
       "       [ 1.982e+03,  1.285e-02],\n",
       "       [ 1.983e+03,  1.395e-02],\n",
       "       [ 1.984e+03,  1.021e-02],\n",
       "       [ 1.985e+03,  3.020e-03],\n",
       "       [ 1.986e+03, -6.060e-03],\n",
       "       [ 1.987e+03, -1.295e-02],\n",
       "       [ 1.988e+03, -1.219e-02],\n",
       "       [ 1.989e+03, -7.700e-04],\n",
       "       [ 1.990e+03,  1.830e-02],\n",
       "       [ 1.991e+03,  3.979e-02],\n",
       "       [ 1.992e+03,  5.591e-02],\n",
       "       [ 1.993e+03,  6.256e-02],\n",
       "       [ 1.994e+03,  5.787e-02],\n",
       "       [ 1.995e+03,  4.725e-02],\n",
       "       [ 1.996e+03,  3.580e-02],\n",
       "       [ 1.997e+03,  2.706e-02],\n",
       "       [ 1.998e+03,  2.137e-02],\n",
       "       [ 1.999e+03,  1.980e-02],\n",
       "       [ 2.000e+03,  2.076e-02],\n",
       "       [ 2.001e+03,  2.251e-02],\n",
       "       [ 2.002e+03,  2.254e-02],\n",
       "       [ 2.003e+03,  2.132e-02],\n",
       "       [ 2.004e+03,  1.773e-02],\n",
       "       [ 2.005e+03,  1.311e-02],\n",
       "       [ 2.006e+03,  8.010e-03],\n",
       "       [ 2.007e+03,  3.850e-03],\n",
       "       [ 2.008e+03,  1.310e-03],\n",
       "       [ 2.009e+03,  9.900e-04],\n",
       "       [ 2.010e+03,  2.130e-03],\n",
       "       [ 2.011e+03,  3.780e-03],\n",
       "       [ 2.012e+03,  5.130e-03],\n",
       "       [ 2.013e+03,  5.950e-03],\n",
       "       [ 2.014e+03,  5.890e-03],\n",
       "       [ 2.015e+03,  5.260e-03],\n",
       "       [ 2.016e+03,  4.610e-03],\n",
       "       [ 2.017e+03,  4.220e-03]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_population_growth_rate_by_country_year(population_df,'ABW')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c584dbd2",
   "metadata": {
    "id": "c584dbd2"
   },
   "source": [
    "Expected output:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71369555",
   "metadata": {
    "id": "71369555"
   },
   "source": [
    "```\n",
    "array([[ 1.961e+03,  2.263e-02],\n",
    "       [ 1.962e+03,  1.420e-02],\n",
    "       [ 1.963e+03,  8.360e-03],\n",
    "       [ 1.964e+03,  5.940e-03],\n",
    "            ...       ....\n",
    "       [ 2.015e+03,  5.260e-03],\n",
    "       [ 2.016e+03,  4.610e-03],\n",
    "       [ 2.017e+03,  4.220e-03]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9b7dc6",
   "metadata": {
    "id": "dc9b7dc6"
   },
   "source": [
    "### Challenge 2: Even-odd train-test split\n",
    "\n",
    "Now that we have our data, we need to divide it into two sets: the variables we will train on and the variables we will predict on. In this scenario, we're separating the variables so that the **training set contains growth rates for even years and the test¬†set contains growth rates for odd years**. We also need to divide our data into the predictive features (`X`) and the response features (`y`).\n",
    "\n",
    "Write a function that will take a 2-D numpy array as input and return four variables in the form of `(X_train, y_train), (X_test, y_test)`, where `(X_train, y_train)` are the features and response variables of the training set, and `(X_test, y_test)` are the features and response variables of the testing set. The training and testing data consist of even and odd years, respectively. The function should return two tuples of the form `(X_train, y_train), (X_test, y_test)`.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take a 2-d numpy `array` as input.\n",
    "* Should return two `tuples` of the form `(X_train, y_train), (X_test, y_test)`.\n",
    "* `(X_train, y_train)` should consist of data from even years and `(X_test, y_test)` should consist of data from odd years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae48fab0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1762871428272,
     "user": {
      "displayName": "olise ossai",
      "userId": "04328672551785049802"
     },
     "user_tz": 360
    },
    "id": "ae48fab0",
    "outputId": "88928312-7634-4ed5-eb4c-6a346028e02d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: [1962. 1964. 1966. 1968. 1970. 1972. 1974. 1976. 1978. 1980. 1982. 1984.\n",
      " 1986. 1988. 1990. 1992. 1994. 1996. 1998. 2000. 2002. 2004. 2006. 2008.\n",
      " 2010. 2012. 2014. 2016.]\n",
      "y_train: [ 0.0142   0.00594  0.00619  0.0057   0.00574  0.00673  0.00473 -0.00117\n",
      " -0.00436  0.00193  0.01285  0.01021 -0.00606 -0.01219  0.0183   0.05591\n",
      "  0.05787  0.0358   0.02137  0.02076  0.02254  0.01773  0.00801  0.00131\n",
      "  0.00213  0.00513  0.00589  0.00461]\n",
      "X_test: [1961. 1963. 1965. 1967. 1969. 1971. 1973. 1975. 1977. 1979. 1981. 1983.\n",
      " 1985. 1987. 1989. 1991. 1993. 1995. 1997. 1999. 2001. 2003. 2005. 2007.\n",
      " 2009. 2011. 2013. 2015. 2017.]\n",
      "y_test: [ 0.02263  0.00836  0.00575  0.00589  0.00582  0.00638  0.00673  0.00213\n",
      " -0.00363 -0.00205  0.00784  0.01395  0.00302 -0.01295 -0.00077  0.03979\n",
      "  0.06256  0.04725  0.02706  0.0198   0.02251  0.02132  0.01311  0.00385\n",
      "  0.00099  0.00378  0.00595  0.00526  0.00422]\n"
     ]
    }
   ],
   "source": [
    "### START FUNCTION\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def feature_response_split(arr):\n",
    "    \"\"\"\n",
    "    Splits the input 2D numpy array into features (X) and response (y), then splits\n",
    "    the data into training (even years) and testing (odd years) sets.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    arr : np.ndarray\n",
    "        A 2D numpy array where each row contains [year, growth_rate].\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    (X_train, y_train), (X_test, y_test)\n",
    "        Tuples containing feature variables (X) and response variable (y)\n",
    "        for both the training (even years) and testing (odd years) datasets.\n",
    "    \"\"\"\n",
    "    # Ensure the input is a numpy array\n",
    "    arr = np.asarray(arr)\n",
    "\n",
    "    # Extract years as features and growth rates as the response variable\n",
    "    X = arr[:, 0]  # Year as feature (1D array)\n",
    "    y = arr[:, 1]  # Growth rate as the response variable (1D array)\n",
    "\n",
    "    # Filter even years for training data\n",
    "    X_train = X[X % 2 == 0]  # Even years for training\n",
    "    y_train = y[X % 2 == 0]  # Growth rates for even years (train)\n",
    "\n",
    "    # Filter odd years for testing data\n",
    "    X_test = X[X % 2 != 0]  # Odd years for testing\n",
    "    y_test = y[X % 2 != 0]  # Growth rates for odd years (test)\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "# Example usage with the function `get_population_growth_rate_by_country_year`:\n",
    "\n",
    "# Assuming you already have the function get_population_growth_rate_by_country_year\n",
    "# that returns the growth rates for a specific country and year range.\n",
    "# Replace this with actual data as required.\n",
    "data = get_population_growth_rate_by_country_year(population_df, 'ABW')\n",
    "\n",
    "# Now, call the function to split the data\n",
    "(X_train, y_train), (X_test, y_test) = feature_response_split(data)\n",
    "\n",
    "# Check the split data\n",
    "print(\"X_train:\", X_train)\n",
    "print(\"y_train:\", y_train)\n",
    "print(\"X_test:\", X_test)\n",
    "print(\"y_test:\", y_test)\n",
    "\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44015d7",
   "metadata": {
    "id": "c44015d7"
   },
   "source": [
    "Input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "edbfa32b",
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1762871444443,
     "user": {
      "displayName": "olise ossai",
      "userId": "04328672551785049802"
     },
     "user_tz": 360
    },
    "id": "edbfa32b"
   },
   "outputs": [],
   "source": [
    "data = get_population_growth_rate_by_country_year(population_df,'ABW');\n",
    "(X_train, y_train), (X_test, y_test) = feature_response_split(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9751dcb",
   "metadata": {
    "id": "c9751dcb"
   },
   "source": [
    "Expected output:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f1efd5",
   "metadata": {
    "id": "e2f1efd5"
   },
   "source": [
    "```\n",
    "y_train ==  array([ 0.01419604,  0.00594409,  0.00618898,  0.00570149,  0.00573851,\n",
    "        0.00672948,  0.00473084, -0.00117052, -0.00435676,  0.00193398,\n",
    "        0.01284528,  0.01020884, -0.00606099, -0.01219414,  0.01830187,\n",
    "        0.05590975,  0.05787267,  0.03580499,  0.02136897,  0.02076288,\n",
    "        0.02254085,  0.01772885,  0.00800752,  0.00131397,  0.00212906,\n",
    "        0.00513459,  0.00589222,  0.00460988])\n",
    "```\n",
    "\n",
    "```\n",
    "X_test == array([1961., 1963., 1965., 1967., 1969., 1971., 1973., 1975., 1977.,\n",
    "       1979., 1981., 1983., 1985., 1987., 1989., 1991., 1993., 1995.,\n",
    "       1997., 1999., 2001., 2003., 2005., 2007., 2009., 2011., 2013.,\n",
    "       2015., 2017.])\n",
    "```\n",
    "\n",
    "```\n",
    "y_test == array([ 0.02263378,  0.00835927,  0.00575116,  0.00589102,  0.00582331,\n",
    "        0.00638301,  0.00673463,  0.00213125, -0.0036312 , -0.00204649,\n",
    "        0.00783746,  0.01395387,  0.00302374, -0.01294617, -0.0007695 ,\n",
    "        0.03979147,  0.0625632 ,  0.04724902,  0.02705529,  0.01979903,\n",
    "        0.02250889,  0.02131758,  0.01310552,  0.00384798,  0.00098665,\n",
    "        0.00377696,  0.00594675,  0.00526037,  0.00421667])      \n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa09265c",
   "metadata": {
    "id": "aa09265c"
   },
   "source": [
    "### Question 3\n",
    "\n",
    "Now that we have formatted our data, we can fit a model using sklearn's `DecisionTreeRegressor` class. We'll write a function that will take as input the features and response variables that we created in the last question, and return a trained model.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take two numpy `arrays` as input in the form `(X_train, y_train)` as well as a `MaxDepth` int corresponding to the max_depth hyperparameter in decision trees.\n",
    "* Should return an sklearn `DecisionTreeRegressor` model.\n",
    "* The returned model should be fitted to the data.\n",
    "\n",
    "_**Hint:**_\n",
    "You may need to reshape the data within the function. You can use `.reshape(-1, 1)` to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22984670",
   "metadata": {
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1762871929591,
     "user": {
      "displayName": "olise ossai",
      "userId": "04328672551785049802"
     },
     "user_tz": 360
    },
    "id": "22984670"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "### START FUNCTION\n",
    "def train_model(X_train, y_train, MaxDepth):\n",
    "    \"\"\"\n",
    "    Train a DecisionTreeRegressor model with the given training data and max depth.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train : np.ndarray\n",
    "        The feature matrix (training data).\n",
    "    y_train : np.ndarray\n",
    "        The target values (growth rates).\n",
    "    MaxDepth : int\n",
    "        The maximum depth of the decision tree.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    model : DecisionTreeRegressor\n",
    "        A trained DecisionTreeRegressor model.\n",
    "    \"\"\"\n",
    "    # Initialize the DecisionTreeRegressor with the given max_depth\n",
    "    model = DecisionTreeRegressor(max_depth=MaxDepth)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train.reshape(-1, 1), y_train)  # Reshape X_train to be 2D (n_samples, n_features)\n",
    "\n",
    "    # Return the trained model\n",
    "    return model\n",
    "### END FUNCTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ab9f5e",
   "metadata": {
    "id": "90ab9f5e"
   },
   "source": [
    "Input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52c5efb1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1762871934207,
     "user": {
      "displayName": "olise ossai",
      "userId": "04328672551785049802"
     },
     "user_tz": 360
    },
    "id": "52c5efb1",
    "outputId": "558924fb-f210-4b57-f94f-6ee4e14a8506"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00451333])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_population_growth_rate_by_country_year(population_df,'ABW')\n",
    "(X_train, y_train), _ = feature_response_split(data)\n",
    "\n",
    "train_model(X_train, y_train,3).predict([[2017]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59712459",
   "metadata": {
    "id": "59712459"
   },
   "source": [
    "Expected output:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8875e2",
   "metadata": {
    "id": "3e8875e2"
   },
   "source": [
    "```\n",
    "array([0.00451333])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a50f5e",
   "metadata": {
    "id": "14a50f5e"
   },
   "source": [
    "### Challenge 4\n",
    "\n",
    "Now we would like to test our model on the testing data that we produced in Exercise 2. This test will give the Root Mean Squared Logarithmic Error (RMSLE), which is determined by:\n",
    "\n",
    "$$\n",
    "RMSLE = \\sqrt{\\frac{1}{N}\\sum_{i=1}^N [log(1+p_i) - log(1+y_i)]^2}\n",
    "$$\n",
    "\n",
    "* *$p_i$ refers to the $i^{\\rm th}$ prediction made from `X_test`\n",
    "* $y_i$ refers to the $i^{\\rm th}$ value in `y_test`\n",
    "* $N$ is the length of `y_test`\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take a trained model and two `arrays` as input. This will be the `X_test` and `y_test` variables from Question 2.\n",
    "* Should calculate and return the Root Mean Squared Logarithmic Error (RMSLE) between the predicted values from `X_test` and the actual values in `y_test`.\n",
    "* The output should be a `float` rounded to 3 decimal places.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b0ea2f8",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1762874019598,
     "user": {
      "displayName": "olise ossai",
      "userId": "04328672551785049802"
     },
     "user_tz": 360
    },
    "id": "3b0ea2f8"
   },
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Assuming model, X_test, and y_test are already defined\n",
    "def test_model(model, y_test, X_test):\n",
    "    \"\"\"\n",
    "    Calculate Root Mean Squared Logarithmic Error (RMSLE) between predictions and actual values.\n",
    "\n",
    "    Parameters:\n",
    "    model : trained model with a .predict() method\n",
    "    y_test (numpy.ndarray): True response values\n",
    "    X_test (numpy.ndarray): Test features\n",
    "\n",
    "    Returns:\n",
    "    float: RMSLE rounded to 3 decimal places\n",
    "    \"\"\"\n",
    "    # Predict using the trained model\n",
    "    y_pred = model.predict(X_test.reshape(-1, 1))  # Reshape X_test to be 2D\n",
    "\n",
    "    # Ensure non-negative values (RMSLE requires this)\n",
    "    y_pred = np.maximum(y_pred, 0)\n",
    "    y_test = np.maximum(y_test, 0)\n",
    "\n",
    "    # Compute RMSLE\n",
    "    log_diff = np.log1p(y_pred) - np.log1p(y_test)\n",
    "    rmsle_value = np.sqrt(np.mean(log_diff ** 2))\n",
    "\n",
    "    return np.round(rmsle_value, 3)\n",
    "\n",
    "### END FUNCTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e50777",
   "metadata": {
    "id": "e9e50777"
   },
   "source": [
    "Input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c1d59c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1762874032324,
     "user": {
      "displayName": "olise ossai",
      "userId": "04328672551785049802"
     },
     "user_tz": 360
    },
    "id": "2c1d59c3",
    "outputId": "116f17e4-55db-4802-f70b-73d8a53ae59d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.007)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = get_population_growth_rate_by_country_year(population_df,'ABW')\n",
    "(X_train, y_train), (X_test, y_test) = feature_response_split(data)\n",
    "lm = train_model(X_train, y_train,3)\n",
    "test_model(lm, y_test, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a986cb0",
   "metadata": {
    "id": "2a986cb0"
   },
   "source": [
    "Expected output:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b154f38",
   "metadata": {
    "id": "9b154f38"
   },
   "source": [
    "```\n",
    "0.008\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62316258",
   "metadata": {
    "id": "62316258"
   },
   "source": [
    "What does this value say about our model?\n",
    "- ‚úçÔ∏è Your notes here\n",
    "\n",
    "The model‚Äôs RMSLE = 0.007, i.e., a very small logarithmic error between predictions and actuals.\n",
    "‚úÖ Interpretation:\n",
    "Your model‚Äôs predictions are extremely close to the actual test values.\n",
    "The average relative difference between the predicted and true values (after taking logs) is less than 1%.\n",
    "In plain terms, your model is performing exceptionally well ‚Äî it predicts the target variable with very high accuracy and minimal variance.\n",
    "\n",
    "üîπ Why RMSLE is small\n",
    "RMSLE penalizes large percentage errors, but is forgiving of small absolute differences when both actual and predicted values are small.\n",
    "So, a value of 0.007 means:\n",
    "The predicted curve aligns almost perfectly with the actual data points.\n",
    "There are no major outliers or large-scale under/over-predictions.\n",
    "The log difference between actual and predicted values is near zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fd094b-0fee-46f1-a4b8-73766813c42b",
   "metadata": {
    "id": "26fd094b-0fee-46f1-a4b8-73766813c42b",
    "tags": []
   },
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "SQL_root",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
